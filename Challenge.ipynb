{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3eb1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.io import read_image\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb04fbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "seed = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc745217",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define custom dataset\n",
    "class CustomDatasetFromCSV(Dataset):\n",
    "    def __init__(self, csv_path, height, width,status,transforms=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.labels = np.asarray(self.data.iloc[:, 0])\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.transforms = transforms\n",
    "        self.status = status\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        single_image_label = self.labels[index]        \n",
    "        img_as_np = np.asarray(self.data.iloc[index][self.status:]).reshape(28,28).astype('uint8')\t\n",
    "        img_as_img = Image.fromarray(img_as_np)\n",
    "\n",
    "        #transform image to tensor\n",
    "        img_as_img = img_as_img.convert('L')    \n",
    "        if self.transforms is not None:\n",
    "            img_as_tensor = self.transforms(img_as_img)       \n",
    "        return (img_as_tensor, single_image_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b93f8659",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create custom dataset\n",
    "transformations = transforms.Compose([transforms.ToTensor()])\n",
    "imageData = CustomDatasetFromCSV('./train.csv',784,784,1, transformations)\n",
    "# testData = CustomDatasetFromCSV('./test.csv',784,784,0, transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d0987ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainData,validationData=train_test_split(imageData,train_size=0.9,random_state=seed)\n",
    "train_loader = DataLoader(trainData, batch_size = 20)\n",
    "validation_loader = DataLoader(validationData,batch_size=20)\n",
    "# test_loader = DataLoader(testData,batch_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82de5134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_data_normal=next(iter(train_loader))\n",
    "fig, ax = plt.subplots(2, 2, figsize = (6, 6))\n",
    "for j in range(0,2):\n",
    "    for i in range(0,2):\n",
    "        ax[i, j].imshow(np.squeeze(vis_data_normal[0][i+(j*2)]), cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ca5dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(6)\n",
    "        # self.conv15 = nn.Conv2d(6,24,5)\n",
    "        self.conv2 = nn.Conv2d(6, 32, 5)\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "        # self.dropout = nn.Dropout(0.25)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.relu(self.conv1_bn(x))\n",
    "        # x = F.max_pool2d(F.relu(self.conv15(x)),2)\n",
    "        # x = F.relu(self.conv15_bn(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.relu(self.conv2_bn(x))\n",
    "        # x = self.dropout(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5a80793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1efae017",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.303350  [    0/37800]\n",
      "loss: 0.425841  [ 2000/37800]\n",
      "loss: 0.298680  [ 4000/37800]\n",
      "loss: 0.282243  [ 6000/37800]\n",
      "loss: 0.142344  [ 8000/37800]\n",
      "loss: 0.114308  [10000/37800]\n",
      "loss: 0.026820  [12000/37800]\n",
      "loss: 0.093147  [14000/37800]\n",
      "loss: 0.090363  [16000/37800]\n",
      "loss: 0.126274  [18000/37800]\n",
      "loss: 0.004889  [20000/37800]\n",
      "loss: 0.014603  [22000/37800]\n",
      "loss: 0.005283  [24000/37800]\n",
      "loss: 0.037943  [26000/37800]\n",
      "loss: 0.155984  [28000/37800]\n",
      "loss: 0.003102  [30000/37800]\n",
      "loss: 0.006125  [32000/37800]\n",
      "loss: 0.007022  [34000/37800]\n",
      "loss: 0.014483  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.054032 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.021478  [    0/37800]\n",
      "loss: 0.018524  [ 2000/37800]\n",
      "loss: 0.175836  [ 4000/37800]\n",
      "loss: 0.290749  [ 6000/37800]\n",
      "loss: 0.020465  [ 8000/37800]\n",
      "loss: 0.035435  [10000/37800]\n",
      "loss: 0.001950  [12000/37800]\n",
      "loss: 0.015420  [14000/37800]\n",
      "loss: 0.015881  [16000/37800]\n",
      "loss: 0.050288  [18000/37800]\n",
      "loss: 0.001044  [20000/37800]\n",
      "loss: 0.005908  [22000/37800]\n",
      "loss: 0.000708  [24000/37800]\n",
      "loss: 0.008739  [26000/37800]\n",
      "loss: 0.088570  [28000/37800]\n",
      "loss: 0.000594  [30000/37800]\n",
      "loss: 0.002504  [32000/37800]\n",
      "loss: 0.010633  [34000/37800]\n",
      "loss: 0.004866  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.046536 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.005977  [    0/37800]\n",
      "loss: 0.010358  [ 2000/37800]\n",
      "loss: 0.042583  [ 4000/37800]\n",
      "loss: 0.107487  [ 6000/37800]\n",
      "loss: 0.020164  [ 8000/37800]\n",
      "loss: 0.023333  [10000/37800]\n",
      "loss: 0.003088  [12000/37800]\n",
      "loss: 0.004565  [14000/37800]\n",
      "loss: 0.018507  [16000/37800]\n",
      "loss: 0.003494  [18000/37800]\n",
      "loss: 0.002124  [20000/37800]\n",
      "loss: 0.058269  [22000/37800]\n",
      "loss: 0.000307  [24000/37800]\n",
      "loss: 0.001497  [26000/37800]\n",
      "loss: 0.031644  [28000/37800]\n",
      "loss: 0.000059  [30000/37800]\n",
      "loss: 0.000654  [32000/37800]\n",
      "loss: 0.000714  [34000/37800]\n",
      "loss: 0.008433  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.043450 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.005258  [    0/37800]\n",
      "loss: 0.027233  [ 2000/37800]\n",
      "loss: 0.058643  [ 4000/37800]\n",
      "loss: 0.085660  [ 6000/37800]\n",
      "loss: 0.019624  [ 8000/37800]\n",
      "loss: 0.077406  [10000/37800]\n",
      "loss: 0.000305  [12000/37800]\n",
      "loss: 0.001545  [14000/37800]\n",
      "loss: 0.004041  [16000/37800]\n",
      "loss: 0.002496  [18000/37800]\n",
      "loss: 0.003402  [20000/37800]\n",
      "loss: 0.002544  [22000/37800]\n",
      "loss: 0.000189  [24000/37800]\n",
      "loss: 0.008122  [26000/37800]\n",
      "loss: 0.023283  [28000/37800]\n",
      "loss: 0.000121  [30000/37800]\n",
      "loss: 0.001461  [32000/37800]\n",
      "loss: 0.000117  [34000/37800]\n",
      "loss: 0.002639  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.038381 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.001950  [    0/37800]\n",
      "loss: 0.002526  [ 2000/37800]\n",
      "loss: 0.038213  [ 4000/37800]\n",
      "loss: 0.044257  [ 6000/37800]\n",
      "loss: 0.004896  [ 8000/37800]\n",
      "loss: 0.004941  [10000/37800]\n",
      "loss: 0.000050  [12000/37800]\n",
      "loss: 0.001675  [14000/37800]\n",
      "loss: 0.000460  [16000/37800]\n",
      "loss: 0.000711  [18000/37800]\n",
      "loss: 0.000079  [20000/37800]\n",
      "loss: 0.002599  [22000/37800]\n",
      "loss: 0.000590  [24000/37800]\n",
      "loss: 0.000086  [26000/37800]\n",
      "loss: 0.012562  [28000/37800]\n",
      "loss: 0.000187  [30000/37800]\n",
      "loss: 0.000424  [32000/37800]\n",
      "loss: 0.000016  [34000/37800]\n",
      "loss: 0.001342  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.045983 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.003894  [    0/37800]\n",
      "loss: 0.003922  [ 2000/37800]\n",
      "loss: 0.040336  [ 4000/37800]\n",
      "loss: 0.030226  [ 6000/37800]\n",
      "loss: 0.001930  [ 8000/37800]\n",
      "loss: 0.029048  [10000/37800]\n",
      "loss: 0.001318  [12000/37800]\n",
      "loss: 0.002977  [14000/37800]\n",
      "loss: 0.000608  [16000/37800]\n",
      "loss: 0.002503  [18000/37800]\n",
      "loss: 0.000078  [20000/37800]\n",
      "loss: 0.000191  [22000/37800]\n",
      "loss: 0.000450  [24000/37800]\n",
      "loss: 0.000200  [26000/37800]\n",
      "loss: 0.006103  [28000/37800]\n",
      "loss: 0.000049  [30000/37800]\n",
      "loss: 0.000061  [32000/37800]\n",
      "loss: 0.000185  [34000/37800]\n",
      "loss: 0.000210  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.060887 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.000821  [    0/37800]\n",
      "loss: 0.004772  [ 2000/37800]\n",
      "loss: 0.003153  [ 4000/37800]\n",
      "loss: 0.006434  [ 6000/37800]\n",
      "loss: 0.024531  [ 8000/37800]\n",
      "loss: 0.001786  [10000/37800]\n",
      "loss: 0.001378  [12000/37800]\n",
      "loss: 0.016193  [14000/37800]\n",
      "loss: 0.000866  [16000/37800]\n",
      "loss: 0.014876  [18000/37800]\n",
      "loss: 0.000224  [20000/37800]\n",
      "loss: 0.000299  [22000/37800]\n",
      "loss: 0.000031  [24000/37800]\n",
      "loss: 0.000125  [26000/37800]\n",
      "loss: 0.006222  [28000/37800]\n",
      "loss: 0.000160  [30000/37800]\n",
      "loss: 0.000020  [32000/37800]\n",
      "loss: 0.000172  [34000/37800]\n",
      "loss: 0.000024  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.062170 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.000427  [    0/37800]\n",
      "loss: 0.355019  [ 2000/37800]\n",
      "loss: 0.033269  [ 4000/37800]\n",
      "loss: 0.035909  [ 6000/37800]\n",
      "loss: 0.000342  [ 8000/37800]\n",
      "loss: 0.001122  [10000/37800]\n",
      "loss: 0.000369  [12000/37800]\n",
      "loss: 0.001462  [14000/37800]\n",
      "loss: 0.012623  [16000/37800]\n",
      "loss: 0.004382  [18000/37800]\n",
      "loss: 0.000666  [20000/37800]\n",
      "loss: 0.000731  [22000/37800]\n",
      "loss: 0.000528  [24000/37800]\n",
      "loss: 0.001215  [26000/37800]\n",
      "loss: 0.007778  [28000/37800]\n",
      "loss: 0.000033  [30000/37800]\n",
      "loss: 0.002330  [32000/37800]\n",
      "loss: 0.000007  [34000/37800]\n",
      "loss: 0.000040  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.065248 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.003328  [    0/37800]\n",
      "loss: 0.000185  [ 2000/37800]\n",
      "loss: 0.003719  [ 4000/37800]\n",
      "loss: 0.044480  [ 6000/37800]\n",
      "loss: 0.322309  [ 8000/37800]\n",
      "loss: 0.000842  [10000/37800]\n",
      "loss: 0.000093  [12000/37800]\n",
      "loss: 0.000074  [14000/37800]\n",
      "loss: 0.000011  [16000/37800]\n",
      "loss: 0.000290  [18000/37800]\n",
      "loss: 0.000023  [20000/37800]\n",
      "loss: 0.000157  [22000/37800]\n",
      "loss: 0.000085  [24000/37800]\n",
      "loss: 0.000024  [26000/37800]\n",
      "loss: 0.056075  [28000/37800]\n",
      "loss: 0.000007  [30000/37800]\n",
      "loss: 0.000063  [32000/37800]\n",
      "loss: 0.000018  [34000/37800]\n",
      "loss: 0.000056  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.058643 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.000250  [    0/37800]\n",
      "loss: 0.000112  [ 2000/37800]\n",
      "loss: 0.021083  [ 4000/37800]\n",
      "loss: 0.000043  [ 6000/37800]\n",
      "loss: 0.000139  [ 8000/37800]\n",
      "loss: 0.000803  [10000/37800]\n",
      "loss: 0.000150  [12000/37800]\n",
      "loss: 0.007832  [14000/37800]\n",
      "loss: 0.000249  [16000/37800]\n",
      "loss: 0.000221  [18000/37800]\n",
      "loss: 0.000039  [20000/37800]\n",
      "loss: 0.000263  [22000/37800]\n",
      "loss: 0.000034  [24000/37800]\n",
      "loss: 0.000008  [26000/37800]\n",
      "loss: 0.005787  [28000/37800]\n",
      "loss: 0.000006  [30000/37800]\n",
      "loss: 0.001110  [32000/37800]\n",
      "loss: 0.000002  [34000/37800]\n",
      "loss: 0.000003  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.064795 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.000196  [    0/37800]\n",
      "loss: 0.040301  [ 2000/37800]\n",
      "loss: 0.008378  [ 4000/37800]\n",
      "loss: 0.001418  [ 6000/37800]\n",
      "loss: 0.001186  [ 8000/37800]\n",
      "loss: 0.000575  [10000/37800]\n",
      "loss: 0.000089  [12000/37800]\n",
      "loss: 0.000036  [14000/37800]\n",
      "loss: 0.000019  [16000/37800]\n",
      "loss: 0.000044  [18000/37800]\n",
      "loss: 0.000043  [20000/37800]\n",
      "loss: 0.000017  [22000/37800]\n",
      "loss: 0.000019  [24000/37800]\n",
      "loss: 0.000001  [26000/37800]\n",
      "loss: 0.022223  [28000/37800]\n",
      "loss: 0.000008  [30000/37800]\n",
      "loss: 0.029030  [32000/37800]\n",
      "loss: 0.000001  [34000/37800]\n",
      "loss: 0.001077  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.064232 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.000143  [    0/37800]\n",
      "loss: 0.000021  [ 2000/37800]\n",
      "loss: 0.002669  [ 4000/37800]\n",
      "loss: 0.010837  [ 6000/37800]\n",
      "loss: 0.002359  [ 8000/37800]\n",
      "loss: 0.095469  [10000/37800]\n",
      "loss: 0.000012  [12000/37800]\n",
      "loss: 0.008210  [14000/37800]\n",
      "loss: 0.000026  [16000/37800]\n",
      "loss: 0.000010  [18000/37800]\n",
      "loss: 0.000043  [20000/37800]\n",
      "loss: 0.000034  [22000/37800]\n",
      "loss: 0.000086  [24000/37800]\n",
      "loss: 0.000100  [26000/37800]\n",
      "loss: 0.001794  [28000/37800]\n",
      "loss: 0.000002  [30000/37800]\n",
      "loss: 0.000160  [32000/37800]\n",
      "loss: 0.000002  [34000/37800]\n",
      "loss: 0.000034  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.073538 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.000083  [    0/37800]\n",
      "loss: 0.000011  [ 2000/37800]\n",
      "loss: 0.018815  [ 4000/37800]\n",
      "loss: 0.003982  [ 6000/37800]\n",
      "loss: 0.000001  [ 8000/37800]\n",
      "loss: 0.003432  [10000/37800]\n",
      "loss: 0.000015  [12000/37800]\n",
      "loss: 0.000021  [14000/37800]\n",
      "loss: 0.000001  [16000/37800]\n",
      "loss: 0.000117  [18000/37800]\n",
      "loss: 0.000018  [20000/37800]\n",
      "loss: 0.001611  [22000/37800]\n",
      "loss: 0.000414  [24000/37800]\n",
      "loss: 0.000002  [26000/37800]\n",
      "loss: 0.035624  [28000/37800]\n",
      "loss: 0.000002  [30000/37800]\n",
      "loss: 0.000787  [32000/37800]\n",
      "loss: 0.000001  [34000/37800]\n",
      "loss: 0.016722  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.063368 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.000322  [    0/37800]\n",
      "loss: 0.000088  [ 2000/37800]\n",
      "loss: 0.022096  [ 4000/37800]\n",
      "loss: 0.056464  [ 6000/37800]\n",
      "loss: 0.000104  [ 8000/37800]\n",
      "loss: 0.000078  [10000/37800]\n",
      "loss: 0.000813  [12000/37800]\n",
      "loss: 0.001640  [14000/37800]\n",
      "loss: 0.000248  [16000/37800]\n",
      "loss: 0.000305  [18000/37800]\n",
      "loss: 0.000015  [20000/37800]\n",
      "loss: 0.000028  [22000/37800]\n",
      "loss: 0.000002  [24000/37800]\n",
      "loss: 0.000007  [26000/37800]\n",
      "loss: 0.004853  [28000/37800]\n",
      "loss: 0.000000  [30000/37800]\n",
      "loss: 0.000016  [32000/37800]\n",
      "loss: 0.000000  [34000/37800]\n",
      "loss: 0.000001  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.082815 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.000329  [    0/37800]\n",
      "loss: 0.000052  [ 2000/37800]\n",
      "loss: 0.000693  [ 4000/37800]\n",
      "loss: 0.000009  [ 6000/37800]\n",
      "loss: 0.000001  [ 8000/37800]\n",
      "loss: 0.000161  [10000/37800]\n",
      "loss: 0.000002  [12000/37800]\n",
      "loss: 0.000669  [14000/37800]\n",
      "loss: 0.000201  [16000/37800]\n",
      "loss: 0.000488  [18000/37800]\n",
      "loss: 0.000004  [20000/37800]\n",
      "loss: 0.000212  [22000/37800]\n",
      "loss: 0.000002  [24000/37800]\n",
      "loss: 0.000000  [26000/37800]\n",
      "loss: 0.000850  [28000/37800]\n",
      "loss: 0.000001  [30000/37800]\n",
      "loss: 0.000049  [32000/37800]\n",
      "loss: 0.000001  [34000/37800]\n",
      "loss: 0.000008  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.067473 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.000298  [    0/37800]\n",
      "loss: 0.000015  [ 2000/37800]\n",
      "loss: 0.002378  [ 4000/37800]\n",
      "loss: 0.000029  [ 6000/37800]\n",
      "loss: 0.000028  [ 8000/37800]\n",
      "loss: 0.000032  [10000/37800]\n",
      "loss: 0.000033  [12000/37800]\n",
      "loss: 0.000264  [14000/37800]\n",
      "loss: 0.000034  [16000/37800]\n",
      "loss: 0.000251  [18000/37800]\n",
      "loss: 0.000013  [20000/37800]\n",
      "loss: 0.000179  [22000/37800]\n",
      "loss: 0.000020  [24000/37800]\n",
      "loss: 0.000001  [26000/37800]\n",
      "loss: 0.000478  [28000/37800]\n",
      "loss: 0.000001  [30000/37800]\n",
      "loss: 0.000060  [32000/37800]\n",
      "loss: 0.000001  [34000/37800]\n",
      "loss: 0.000002  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.070392 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.000018  [    0/37800]\n",
      "loss: 0.000003  [ 2000/37800]\n",
      "loss: 0.126661  [ 4000/37800]\n",
      "loss: 0.000259  [ 6000/37800]\n",
      "loss: 0.000005  [ 8000/37800]\n",
      "loss: 0.005835  [10000/37800]\n",
      "loss: 0.000000  [12000/37800]\n",
      "loss: 0.000093  [14000/37800]\n",
      "loss: 0.000002  [16000/37800]\n",
      "loss: 0.000067  [18000/37800]\n",
      "loss: 0.000006  [20000/37800]\n",
      "loss: 0.000736  [22000/37800]\n",
      "loss: 0.000011  [24000/37800]\n",
      "loss: 0.000000  [26000/37800]\n",
      "loss: 0.000653  [28000/37800]\n",
      "loss: 0.000000  [30000/37800]\n",
      "loss: 0.004454  [32000/37800]\n",
      "loss: 0.000000  [34000/37800]\n",
      "loss: 0.000001  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.059127 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.012579  [    0/37800]\n",
      "loss: 0.000002  [ 2000/37800]\n",
      "loss: 0.061823  [ 4000/37800]\n",
      "loss: 0.000060  [ 6000/37800]\n",
      "loss: 0.000002  [ 8000/37800]\n",
      "loss: 0.000470  [10000/37800]\n",
      "loss: 0.000013  [12000/37800]\n",
      "loss: 0.000055  [14000/37800]\n",
      "loss: 0.000001  [16000/37800]\n",
      "loss: 0.000463  [18000/37800]\n",
      "loss: 0.000003  [20000/37800]\n",
      "loss: 0.000002  [22000/37800]\n",
      "loss: 0.000000  [24000/37800]\n",
      "loss: 0.000000  [26000/37800]\n",
      "loss: 0.001677  [28000/37800]\n",
      "loss: 0.000001  [30000/37800]\n",
      "loss: 0.000326  [32000/37800]\n",
      "loss: 0.000000  [34000/37800]\n",
      "loss: 0.000000  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.072310 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/37800]\n",
      "loss: 0.000007  [ 2000/37800]\n",
      "loss: 0.004659  [ 4000/37800]\n",
      "loss: 0.006448  [ 6000/37800]\n",
      "loss: 0.000000  [ 8000/37800]\n",
      "loss: 0.030169  [10000/37800]\n",
      "loss: 0.000002  [12000/37800]\n",
      "loss: 0.000231  [14000/37800]\n",
      "loss: 0.000002  [16000/37800]\n",
      "loss: 0.000163  [18000/37800]\n",
      "loss: 0.000037  [20000/37800]\n",
      "loss: 0.000001  [22000/37800]\n",
      "loss: 0.003756  [24000/37800]\n",
      "loss: 0.000001  [26000/37800]\n",
      "loss: 0.000950  [28000/37800]\n",
      "loss: 0.000002  [30000/37800]\n",
      "loss: 0.000113  [32000/37800]\n",
      "loss: 0.000000  [34000/37800]\n",
      "loss: 0.000008  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.063044 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.163420  [    0/37800]\n",
      "loss: 0.000000  [ 2000/37800]\n",
      "loss: 0.003156  [ 4000/37800]\n",
      "loss: 0.000001  [ 6000/37800]\n",
      "loss: 0.000004  [ 8000/37800]\n",
      "loss: 0.000294  [10000/37800]\n",
      "loss: 0.000000  [12000/37800]\n",
      "loss: 0.005429  [14000/37800]\n",
      "loss: 0.000000  [16000/37800]\n",
      "loss: 0.000387  [18000/37800]\n",
      "loss: 0.000001  [20000/37800]\n",
      "loss: 0.000004  [22000/37800]\n",
      "loss: 0.000003  [24000/37800]\n",
      "loss: 0.000000  [26000/37800]\n",
      "loss: 0.004842  [28000/37800]\n",
      "loss: 0.000000  [30000/37800]\n",
      "loss: 0.000023  [32000/37800]\n",
      "loss: 0.000000  [34000/37800]\n",
      "loss: 0.000000  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.081085 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),0.0005)\n",
    "total_step = len(train_loader)\n",
    "epoch = 20\n",
    "model.train()\n",
    "for t in range(epoch):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    test_loop(validation_loader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6020e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'./model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "128cb4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitDataset(Dataset):\n",
    "    def __init__(self,X):\n",
    "        self.image = X/255 \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image = self.image[idx]\n",
    "        return torch.FloatTensor(image)\n",
    "test_dir = './test.csv'\n",
    "test_data = pd.read_csv(test_dir)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_data = test_data.reshape(-1,1,28,28)\n",
    "tensor_test = DigitDataset(test_data)\n",
    "test_loader = DataLoader(tensor_test, batch_size = 1)\n",
    "nn_model = NeuralNetwork()\n",
    "nn_model.load_state_dict(torch.load('./model.pth'))\n",
    "\n",
    "def test():\n",
    "    nn_model.eval()\n",
    "    submission = pd.DataFrame(columns=['ImageId','Label'])\n",
    "    id = 1 #It has to start in 1 accordingly to the rules\n",
    "    id_list = []\n",
    "    guess = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            outputs = nn_model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            id_list.append(id)\n",
    "            guess.append(predicted.item())\n",
    "            id+=1\n",
    "            \n",
    "    submission['ImageId'] = id_list\n",
    "    submission['Label'] = guess\n",
    "    \n",
    "    submission.to_csv(\"submission.csv\",index=False)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6139160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28000/28000 [00:06<00:00, 4264.23it/s]\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e282164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d35586b6854ae70032a86b767a712e3a4af1f166395c8db1ad1dec3054479611"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
