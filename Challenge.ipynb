{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3eb1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.io import read_image\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb04fbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "seed = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc745217",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define custom dataset\n",
    "class CustomDatasetFromCSV(Dataset):\n",
    "    def __init__(self, csv_path, height, width,status,transforms=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.labels = np.asarray(self.data.iloc[:, 0])\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.transforms = transforms\n",
    "        self.status = status\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        single_image_label = self.labels[index]        \n",
    "        img_as_np = np.asarray(self.data.iloc[index][self.status:]).reshape(28,28).astype('uint8')\t\n",
    "        img_as_img = Image.fromarray(img_as_np)\n",
    "        #transform image to tensor\n",
    "        img_as_img = img_as_img.convert('L')    \n",
    "        if self.transforms is not None:\n",
    "            img_as_tensor = self.transforms(img_as_img)       \n",
    "        return (img_as_tensor, single_image_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b93f8659",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create custom dataset\n",
    "transformations = transforms.Compose([transforms.ToTensor()])\n",
    "imageData = CustomDatasetFromCSV('./train.csv',784,784,1, transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d0987ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainData,validationData=train_test_split(imageData,train_size=0.95,random_state=seed)\n",
    "train_loader = DataLoader(trainData, batch_size = 20)\n",
    "validation_loader = DataLoader(validationData,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82de5134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_data_normal=next(iter(train_loader))\n",
    "fig, ax = plt.subplots(2, 2, figsize = (6, 6))\n",
    "for j in range(0,2):\n",
    "    for i in range(0,2):\n",
    "        ax[i, j].imshow(np.squeeze(vis_data_normal[0][i+(j*2)]), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ca5dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.relu(self.conv1_bn(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.relu(self.conv2_bn(x))\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5a80793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1efae017",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.297296  [    0/37800]\n",
      "loss: 0.320106  [ 2000/37800]\n",
      "loss: 0.318940  [ 4000/37800]\n",
      "loss: 0.205226  [ 6000/37800]\n",
      "loss: 0.112888  [ 8000/37800]\n",
      "loss: 0.122423  [10000/37800]\n",
      "loss: 0.055831  [12000/37800]\n",
      "loss: 0.008835  [14000/37800]\n",
      "loss: 0.017557  [16000/37800]\n",
      "loss: 0.068988  [18000/37800]\n",
      "loss: 0.002631  [20000/37800]\n",
      "loss: 0.015896  [22000/37800]\n",
      "loss: 0.001510  [24000/37800]\n",
      "loss: 0.000426  [26000/37800]\n",
      "loss: 0.147731  [28000/37800]\n",
      "loss: 0.002011  [30000/37800]\n",
      "loss: 0.005051  [32000/37800]\n",
      "loss: 0.002247  [34000/37800]\n",
      "loss: 0.015378  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.038890 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.006609  [    0/37800]\n",
      "loss: 0.035932  [ 2000/37800]\n",
      "loss: 0.090229  [ 4000/37800]\n",
      "loss: 0.034019  [ 6000/37800]\n",
      "loss: 0.003008  [ 8000/37800]\n",
      "loss: 0.164442  [10000/37800]\n",
      "loss: 0.004148  [12000/37800]\n",
      "loss: 0.002712  [14000/37800]\n",
      "loss: 0.004605  [16000/37800]\n",
      "loss: 0.028854  [18000/37800]\n",
      "loss: 0.000525  [20000/37800]\n",
      "loss: 0.145164  [22000/37800]\n",
      "loss: 0.000860  [24000/37800]\n",
      "loss: 0.000125  [26000/37800]\n",
      "loss: 0.050202  [28000/37800]\n",
      "loss: 0.000170  [30000/37800]\n",
      "loss: 0.000710  [32000/37800]\n",
      "loss: 0.000473  [34000/37800]\n",
      "loss: 0.013560  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.038359 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.004463  [    0/37800]\n",
      "loss: 0.021654  [ 2000/37800]\n",
      "loss: 0.069812  [ 4000/37800]\n",
      "loss: 0.054100  [ 6000/37800]\n",
      "loss: 0.010755  [ 8000/37800]\n",
      "loss: 0.004621  [10000/37800]\n",
      "loss: 0.002458  [12000/37800]\n",
      "loss: 0.004653  [14000/37800]\n",
      "loss: 0.059240  [16000/37800]\n",
      "loss: 0.001301  [18000/37800]\n",
      "loss: 0.004382  [20000/37800]\n",
      "loss: 0.000399  [22000/37800]\n",
      "loss: 0.000235  [24000/37800]\n",
      "loss: 0.000042  [26000/37800]\n",
      "loss: 0.021415  [28000/37800]\n",
      "loss: 0.000096  [30000/37800]\n",
      "loss: 0.002532  [32000/37800]\n",
      "loss: 0.000333  [34000/37800]\n",
      "loss: 0.003168  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.034710 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.002339  [    0/37800]\n",
      "loss: 0.001795  [ 2000/37800]\n",
      "loss: 0.021177  [ 4000/37800]\n",
      "loss: 0.002312  [ 6000/37800]\n",
      "loss: 0.003348  [ 8000/37800]\n",
      "loss: 0.016812  [10000/37800]\n",
      "loss: 0.002494  [12000/37800]\n",
      "loss: 0.000333  [14000/37800]\n",
      "loss: 0.000286  [16000/37800]\n",
      "loss: 0.000683  [18000/37800]\n",
      "loss: 0.000079  [20000/37800]\n",
      "loss: 0.003153  [22000/37800]\n",
      "loss: 0.000362  [24000/37800]\n",
      "loss: 0.000020  [26000/37800]\n",
      "loss: 0.005706  [28000/37800]\n",
      "loss: 0.000311  [30000/37800]\n",
      "loss: 0.000295  [32000/37800]\n",
      "loss: 0.000026  [34000/37800]\n",
      "loss: 0.000147  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.047687 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.000141  [    0/37800]\n",
      "loss: 0.000269  [ 2000/37800]\n",
      "loss: 0.026290  [ 4000/37800]\n",
      "loss: 0.018467  [ 6000/37800]\n",
      "loss: 0.008074  [ 8000/37800]\n",
      "loss: 0.001234  [10000/37800]\n",
      "loss: 0.000409  [12000/37800]\n",
      "loss: 0.000835  [14000/37800]\n",
      "loss: 0.000134  [16000/37800]\n",
      "loss: 0.001951  [18000/37800]\n",
      "loss: 0.000053  [20000/37800]\n",
      "loss: 0.000039  [22000/37800]\n",
      "loss: 0.000302  [24000/37800]\n",
      "loss: 0.000004  [26000/37800]\n",
      "loss: 0.021997  [28000/37800]\n",
      "loss: 0.000022  [30000/37800]\n",
      "loss: 0.001783  [32000/37800]\n",
      "loss: 0.000004  [34000/37800]\n",
      "loss: 0.000327  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.042647 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.011634  [    0/37800]\n",
      "loss: 0.000658  [ 2000/37800]\n",
      "loss: 0.071254  [ 4000/37800]\n",
      "loss: 0.002930  [ 6000/37800]\n",
      "loss: 0.001269  [ 8000/37800]\n",
      "loss: 0.059224  [10000/37800]\n",
      "loss: 0.000086  [12000/37800]\n",
      "loss: 0.000817  [14000/37800]\n",
      "loss: 0.000030  [16000/37800]\n",
      "loss: 0.000380  [18000/37800]\n",
      "loss: 0.000010  [20000/37800]\n",
      "loss: 0.000100  [22000/37800]\n",
      "loss: 0.000169  [24000/37800]\n",
      "loss: 0.000003  [26000/37800]\n",
      "loss: 0.007373  [28000/37800]\n",
      "loss: 0.000055  [30000/37800]\n",
      "loss: 0.000158  [32000/37800]\n",
      "loss: 0.000012  [34000/37800]\n",
      "loss: 0.000192  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.046728 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.002049  [    0/37800]\n",
      "loss: 0.000421  [ 2000/37800]\n",
      "loss: 0.126387  [ 4000/37800]\n",
      "loss: 0.011653  [ 6000/37800]\n",
      "loss: 0.000105  [ 8000/37800]\n",
      "loss: 0.000144  [10000/37800]\n",
      "loss: 0.000135  [12000/37800]\n",
      "loss: 0.000449  [14000/37800]\n",
      "loss: 0.000376  [16000/37800]\n",
      "loss: 0.003930  [18000/37800]\n",
      "loss: 0.000017  [20000/37800]\n",
      "loss: 0.009835  [22000/37800]\n",
      "loss: 0.000334  [24000/37800]\n",
      "loss: 0.000001  [26000/37800]\n",
      "loss: 0.020924  [28000/37800]\n",
      "loss: 0.000005  [30000/37800]\n",
      "loss: 0.000035  [32000/37800]\n",
      "loss: 0.000021  [34000/37800]\n",
      "loss: 0.000007  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.051703 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.001648  [    0/37800]\n",
      "loss: 0.012581  [ 2000/37800]\n",
      "loss: 0.004859  [ 4000/37800]\n",
      "loss: 0.003263  [ 6000/37800]\n",
      "loss: 0.004906  [ 8000/37800]\n",
      "loss: 0.000052  [10000/37800]\n",
      "loss: 0.000011  [12000/37800]\n",
      "loss: 0.000303  [14000/37800]\n",
      "loss: 0.000011  [16000/37800]\n",
      "loss: 0.000026  [18000/37800]\n",
      "loss: 0.000028  [20000/37800]\n",
      "loss: 0.000028  [22000/37800]\n",
      "loss: 0.000654  [24000/37800]\n",
      "loss: 0.000002  [26000/37800]\n",
      "loss: 0.024621  [28000/37800]\n",
      "loss: 0.000001  [30000/37800]\n",
      "loss: 0.000019  [32000/37800]\n",
      "loss: 0.000007  [34000/37800]\n",
      "loss: 0.000058  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.050256 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.000119  [    0/37800]\n",
      "loss: 0.001288  [ 2000/37800]\n",
      "loss: 0.009999  [ 4000/37800]\n",
      "loss: 0.077207  [ 6000/37800]\n",
      "loss: 0.193147  [ 8000/37800]\n",
      "loss: 0.000072  [10000/37800]\n",
      "loss: 0.000020  [12000/37800]\n",
      "loss: 0.000131  [14000/37800]\n",
      "loss: 0.000004  [16000/37800]\n",
      "loss: 0.000155  [18000/37800]\n",
      "loss: 0.000140  [20000/37800]\n",
      "loss: 0.000004  [22000/37800]\n",
      "loss: 0.000004  [24000/37800]\n",
      "loss: 0.000421  [26000/37800]\n",
      "loss: 0.089537  [28000/37800]\n",
      "loss: 0.000001  [30000/37800]\n",
      "loss: 0.000097  [32000/37800]\n",
      "loss: 0.000009  [34000/37800]\n",
      "loss: 0.000042  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.047330 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.003567  [    0/37800]\n",
      "loss: 0.010613  [ 2000/37800]\n",
      "loss: 0.129811  [ 4000/37800]\n",
      "loss: 0.000081  [ 6000/37800]\n",
      "loss: 0.000032  [ 8000/37800]\n",
      "loss: 0.000395  [10000/37800]\n",
      "loss: 0.000116  [12000/37800]\n",
      "loss: 0.006283  [14000/37800]\n",
      "loss: 0.000004  [16000/37800]\n",
      "loss: 0.000301  [18000/37800]\n",
      "loss: 0.000016  [20000/37800]\n",
      "loss: 0.000043  [22000/37800]\n",
      "loss: 0.000056  [24000/37800]\n",
      "loss: 0.000002  [26000/37800]\n",
      "loss: 0.005368  [28000/37800]\n",
      "loss: 0.000001  [30000/37800]\n",
      "loss: 0.000014  [32000/37800]\n",
      "loss: 0.000131  [34000/37800]\n",
      "loss: 0.000053  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.054390 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.000679  [    0/37800]\n",
      "loss: 0.000647  [ 2000/37800]\n",
      "loss: 0.074864  [ 4000/37800]\n",
      "loss: 0.000307  [ 6000/37800]\n",
      "loss: 0.000025  [ 8000/37800]\n",
      "loss: 0.002130  [10000/37800]\n",
      "loss: 0.000015  [12000/37800]\n",
      "loss: 0.000062  [14000/37800]\n",
      "loss: 0.000060  [16000/37800]\n",
      "loss: 0.000016  [18000/37800]\n",
      "loss: 0.000004  [20000/37800]\n",
      "loss: 0.000114  [22000/37800]\n",
      "loss: 0.000039  [24000/37800]\n",
      "loss: 0.000000  [26000/37800]\n",
      "loss: 0.064666  [28000/37800]\n",
      "loss: 0.000001  [30000/37800]\n",
      "loss: 0.089524  [32000/37800]\n",
      "loss: 0.000012  [34000/37800]\n",
      "loss: 0.000168  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.048306 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.000166  [    0/37800]\n",
      "loss: 0.004904  [ 2000/37800]\n",
      "loss: 0.001010  [ 4000/37800]\n",
      "loss: 0.000137  [ 6000/37800]\n",
      "loss: 0.000034  [ 8000/37800]\n",
      "loss: 0.007438  [10000/37800]\n",
      "loss: 0.000154  [12000/37800]\n",
      "loss: 0.001834  [14000/37800]\n",
      "loss: 0.203895  [16000/37800]\n",
      "loss: 0.000032  [18000/37800]\n",
      "loss: 0.000188  [20000/37800]\n",
      "loss: 0.000011  [22000/37800]\n",
      "loss: 0.000066  [24000/37800]\n",
      "loss: 0.000000  [26000/37800]\n",
      "loss: 0.000328  [28000/37800]\n",
      "loss: 0.000002  [30000/37800]\n",
      "loss: 0.000000  [32000/37800]\n",
      "loss: 0.000000  [34000/37800]\n",
      "loss: 0.000027  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.052872 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.000075  [    0/37800]\n",
      "loss: 0.000015  [ 2000/37800]\n",
      "loss: 0.002179  [ 4000/37800]\n",
      "loss: 0.039932  [ 6000/37800]\n",
      "loss: 0.000336  [ 8000/37800]\n",
      "loss: 0.000009  [10000/37800]\n",
      "loss: 0.005573  [12000/37800]\n",
      "loss: 0.000292  [14000/37800]\n",
      "loss: 0.000003  [16000/37800]\n",
      "loss: 0.000201  [18000/37800]\n",
      "loss: 0.000297  [20000/37800]\n",
      "loss: 0.007870  [22000/37800]\n",
      "loss: 0.000001  [24000/37800]\n",
      "loss: 0.000001  [26000/37800]\n",
      "loss: 0.000308  [28000/37800]\n",
      "loss: 0.000000  [30000/37800]\n",
      "loss: 0.000000  [32000/37800]\n",
      "loss: 0.000014  [34000/37800]\n",
      "loss: 0.000018  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.051271 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/37800]\n",
      "loss: 0.009356  [ 2000/37800]\n",
      "loss: 0.100948  [ 4000/37800]\n",
      "loss: 0.001647  [ 6000/37800]\n",
      "loss: 0.000252  [ 8000/37800]\n",
      "loss: 0.000029  [10000/37800]\n",
      "loss: 0.000003  [12000/37800]\n",
      "loss: 0.012806  [14000/37800]\n",
      "loss: 0.000000  [16000/37800]\n",
      "loss: 0.000000  [18000/37800]\n",
      "loss: 0.000001  [20000/37800]\n",
      "loss: 0.000001  [22000/37800]\n",
      "loss: 0.000218  [24000/37800]\n",
      "loss: 0.000000  [26000/37800]\n",
      "loss: 0.000212  [28000/37800]\n",
      "loss: 0.000001  [30000/37800]\n",
      "loss: 0.000001  [32000/37800]\n",
      "loss: 0.000000  [34000/37800]\n",
      "loss: 0.000001  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.054081 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.000047  [    0/37800]\n",
      "loss: 0.009673  [ 2000/37800]\n",
      "loss: 0.005387  [ 4000/37800]\n",
      "loss: 0.000512  [ 6000/37800]\n",
      "loss: 0.000045  [ 8000/37800]\n",
      "loss: 0.000001  [10000/37800]\n",
      "loss: 0.000027  [12000/37800]\n",
      "loss: 0.016441  [14000/37800]\n",
      "loss: 0.000009  [16000/37800]\n",
      "loss: 0.002976  [18000/37800]\n",
      "loss: 0.000101  [20000/37800]\n",
      "loss: 0.000097  [22000/37800]\n",
      "loss: 0.000003  [24000/37800]\n",
      "loss: 0.000000  [26000/37800]\n",
      "loss: 0.000683  [28000/37800]\n",
      "loss: 0.000000  [30000/37800]\n",
      "loss: 0.000000  [32000/37800]\n",
      "loss: 0.000000  [34000/37800]\n",
      "loss: 0.000000  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.055248 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.000075  [    0/37800]\n",
      "loss: 0.000005  [ 2000/37800]\n",
      "loss: 0.001130  [ 4000/37800]\n",
      "loss: 0.000157  [ 6000/37800]\n",
      "loss: 0.000004  [ 8000/37800]\n",
      "loss: 0.004443  [10000/37800]\n",
      "loss: 0.000000  [12000/37800]\n",
      "loss: 0.000036  [14000/37800]\n",
      "loss: 0.000007  [16000/37800]\n",
      "loss: 0.000263  [18000/37800]\n",
      "loss: 0.000001  [20000/37800]\n",
      "loss: 0.000003  [22000/37800]\n",
      "loss: 0.000005  [24000/37800]\n",
      "loss: 0.000002  [26000/37800]\n",
      "loss: 0.007228  [28000/37800]\n",
      "loss: 0.000000  [30000/37800]\n",
      "loss: 0.000000  [32000/37800]\n",
      "loss: 0.000000  [34000/37800]\n",
      "loss: 0.000005  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.072668 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/37800]\n",
      "loss: 0.000002  [ 2000/37800]\n",
      "loss: 0.000565  [ 4000/37800]\n",
      "loss: 0.000108  [ 6000/37800]\n",
      "loss: 0.005170  [ 8000/37800]\n",
      "loss: 0.000019  [10000/37800]\n",
      "loss: 0.000001  [12000/37800]\n",
      "loss: 0.040617  [14000/37800]\n",
      "loss: 0.000000  [16000/37800]\n",
      "loss: 0.000122  [18000/37800]\n",
      "loss: 0.000009  [20000/37800]\n",
      "loss: 0.000783  [22000/37800]\n",
      "loss: 0.000028  [24000/37800]\n",
      "loss: 0.000000  [26000/37800]\n",
      "loss: 0.001044  [28000/37800]\n",
      "loss: 0.000003  [30000/37800]\n",
      "loss: 0.000000  [32000/37800]\n",
      "loss: 0.000000  [34000/37800]\n",
      "loss: 0.000001  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.052948 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.000012  [    0/37800]\n",
      "loss: 0.000002  [ 2000/37800]\n",
      "loss: 0.001099  [ 4000/37800]\n",
      "loss: 0.000024  [ 6000/37800]\n",
      "loss: 0.000027  [ 8000/37800]\n",
      "loss: 0.000109  [10000/37800]\n",
      "loss: 0.000000  [12000/37800]\n",
      "loss: 0.001677  [14000/37800]\n",
      "loss: 0.000019  [16000/37800]\n",
      "loss: 0.000264  [18000/37800]\n",
      "loss: 0.000009  [20000/37800]\n",
      "loss: 0.000000  [22000/37800]\n",
      "loss: 0.000007  [24000/37800]\n",
      "loss: 0.000000  [26000/37800]\n",
      "loss: 0.000363  [28000/37800]\n",
      "loss: 0.000000  [30000/37800]\n",
      "loss: 0.000000  [32000/37800]\n",
      "loss: 0.000005  [34000/37800]\n",
      "loss: 0.000032  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.054457 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.000115  [    0/37800]\n",
      "loss: 0.000007  [ 2000/37800]\n",
      "loss: 0.029725  [ 4000/37800]\n",
      "loss: 0.000078  [ 6000/37800]\n",
      "loss: 0.000000  [ 8000/37800]\n",
      "loss: 0.356466  [10000/37800]\n",
      "loss: 0.000001  [12000/37800]\n",
      "loss: 0.000235  [14000/37800]\n",
      "loss: 0.000000  [16000/37800]\n",
      "loss: 0.005771  [18000/37800]\n",
      "loss: 0.000000  [20000/37800]\n",
      "loss: 0.000001  [22000/37800]\n",
      "loss: 0.000001  [24000/37800]\n",
      "loss: 0.000000  [26000/37800]\n",
      "loss: 0.000280  [28000/37800]\n",
      "loss: 0.000000  [30000/37800]\n",
      "loss: 0.000000  [32000/37800]\n",
      "loss: 0.000000  [34000/37800]\n",
      "loss: 0.000085  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.068392 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.000686  [    0/37800]\n",
      "loss: 0.000001  [ 2000/37800]\n",
      "loss: 0.000006  [ 4000/37800]\n",
      "loss: 0.002713  [ 6000/37800]\n",
      "loss: 0.000126  [ 8000/37800]\n",
      "loss: 0.000849  [10000/37800]\n",
      "loss: 0.000000  [12000/37800]\n",
      "loss: 0.000019  [14000/37800]\n",
      "loss: 0.000000  [16000/37800]\n",
      "loss: 0.000005  [18000/37800]\n",
      "loss: 0.000005  [20000/37800]\n",
      "loss: 0.000000  [22000/37800]\n",
      "loss: 0.000001  [24000/37800]\n",
      "loss: 0.000000  [26000/37800]\n",
      "loss: 0.010684  [28000/37800]\n",
      "loss: 0.000000  [30000/37800]\n",
      "loss: 0.000001  [32000/37800]\n",
      "loss: 0.000000  [34000/37800]\n",
      "loss: 0.000000  [36000/37800]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.065713 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),0.0005)\n",
    "total_step = len(train_loader)\n",
    "epoch = 20\n",
    "model.train()\n",
    "for t in range(epoch):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    test_loop(validation_loader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6020e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'./model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "128cb4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitDataset(Dataset):\n",
    "    def __init__(self,X):\n",
    "        self.image = X/255 \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image = self.image[idx]\n",
    "        return torch.FloatTensor(image)\n",
    "test_dir = './test.csv'\n",
    "test_data = pd.read_csv(test_dir)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_data = test_data.reshape(-1,1,28,28)\n",
    "tensor_test = DigitDataset(test_data)\n",
    "test_loader = DataLoader(tensor_test, batch_size = 1)\n",
    "nn_model = NeuralNetwork()\n",
    "nn_model.load_state_dict(torch.load('./model.pth'))\n",
    "\n",
    "def test():\n",
    "    nn_model.eval()\n",
    "    submission = pd.DataFrame(columns=['ImageId','Label'])\n",
    "    id = 1 #It has to start in 1 accordingly to the rules\n",
    "    id_list = []\n",
    "    guess = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            outputs = nn_model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            id_list.append(id)\n",
    "            guess.append(predicted.item())\n",
    "            id+=1\n",
    "            \n",
    "    submission['ImageId'] = id_list\n",
    "    submission['Label'] = guess\n",
    "    \n",
    "    submission.to_csv(\"submission.csv\",index=False)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6139160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28000/28000 [00:11<00:00, 2459.73it/s]\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d35586b6854ae70032a86b767a712e3a4af1f166395c8db1ad1dec3054479611"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
